---
marp: true
html: true
theme: default
paginate: true
---
<style>
.dodgerblue {
  color: dodgerblue;
}
.indianred {
  color: indianred;
}
</style>
# ğŸ³ğŸ¤– Docker Model Runner (**DMR**)

- Docker plugin `==` <span class="dodgerblue">**LLM Engine**</span> (based on llama.cpp)
  - **DMR Base URLs:**
    - From Containers: `http://model-runner.docker.internal/`
    - From Host: `http://localhost:12434/`
  - <span class="indianred">**OpenAI API Compatible**</span> (ex: ğŸ¦™Ollama, AI frameworks...)


```bash terminal-id=terminal-02
curl http://model-runner.docker.internal/engines/v1/chat/completions \
    -H "Content-Type: application/json" \
    -d '{
        "model": "ai/qwen2.5:0.5B-F16",
        "messages": [{"role": "user", "content": "ğŸ–– Who is Spock?"}]
    }'
```