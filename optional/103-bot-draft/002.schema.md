# Interactive Bot Chat

```mermaid
flowchart TD
    Start([Start]):::start

    Start --> LoadEnv[<a href="/103-bot-draft/main.go#L18">Load Environment Variables</a>]:::config

    LoadEnv --> CreateClient[<a href="/103-bot-draft/main.go#L21">Create OpenAI Client</a>]:::client

    CreateClient --> ChatLoop{<a href="/103-bot-draft/main.go#L34">Chat Loop</a>}:::loop

    ChatLoop --> ShowPrompt[<a href="/103-bot-draft/main.go#L36">Show Bot Prompt</a>]:::prompt

    ShowPrompt --> ReadInput[<a href="/103-bot-draft/main.go#L37">Read User Input</a>]:::input

    ReadInput --> CheckExit{<a href="/103-bot-draft/main.go#L39">Is /bye?</a>}:::decision

    CheckExit -->|Yes| Goodbye[<a href="/103-bot-draft/main.go#L40">Say Goodbye</a>]:::exit

    Goodbye --> EndNode([End]):::final

    CheckExit -->|No| PrepareMessages[<a href="/103-bot-draft/main.go#L44">Prepare Messages</a>]:::message

    PrepareMessages --> StartStream[<a href="/103-bot-draft/main.go#L56">Start Streaming</a>]:::stream

    StartStream --> StreamChunks[<a href="/103-bot-draft/main.go#L60">Stream Response Chunks</a>]:::output

    StreamChunks --> CheckError{<a href="/103-bot-draft/main.go#L68">Stream Error?</a>}:::decision

    CheckError -->|Yes| ErrorExit[<a href="/103-bot-draft/main.go#L69">Log Fatal Error</a>]:::error

    CheckError -->|No| PrintSeparator[<a href="/103-bot-draft/main.go#L71">Print Separator</a>]:::separator

    PrintSeparator --> ChatLoop

    classDef start fill:#e8f5e8,stroke:#2e7d32,stroke-width:3px,color:#000
    classDef config fill:#fff3e0,stroke:#f57c00,stroke-width:2px,color:#000
    classDef client fill:#e3f2fd,stroke:#1976d2,stroke-width:2px,color:#000
    classDef loop fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px,color:#000
    classDef prompt fill:#e8eaf6,stroke:#3f51b5,stroke-width:2px,color:#000
    classDef input fill:#fff8e1,stroke:#f9a825,stroke-width:2px,color:#000
    classDef decision fill:#fff8e1,stroke:#f9a825,stroke-width:2px,color:#000
    classDef exit fill:#ffebee,stroke:#d32f2f,stroke-width:2px,color:#000
    classDef final fill:#fce4ec,stroke:#c2185b,stroke-width:3px,color:#000
    classDef message fill:#e0f2f1,stroke:#388e3c,stroke-width:2px,color:#000
    classDef stream fill:#e1f5fe,stroke:#0277bd,stroke-width:2px,color:#000
    classDef output fill:#e0f4ff,stroke:#0288d1,stroke-width:2px,color:#000
    classDef error fill:#ffebee,stroke:#d32f2f,stroke-width:2px,color:#000
    classDef separator fill:#f1f8e9,stroke:#33691e,stroke-width:2px,color:#000
```

**Flow Summary:**
1. **Load Environment**: Get all configuration (URL, model, agent name, instructions, temperature, top_p)
2. **Create Client**: Initialize OpenAI client with custom configuration
3. **Chat Loop**: Enter continuous conversation mode
4. **Show Prompt**: Display bot name and model in interactive prompt
5. **Read Input**: Get user message from stdin
6. **Check Exit**: Look for `/bye` command to exit
7. **Prepare Messages**: Create system + user message pair
8. **Start Stream**: Begin streaming completion request
9. **Stream Chunks**: Output response in real-time as it's generated
10. **Error Check**: Handle any streaming errors
11. **Print Separator**: Add visual break between conversations
12. **Loop Back**: Return to prompt for next interaction

**Key Features:**
- **Interactive Loop**: Continuous conversation until `/bye`
- **Real-time Streaming**: Responses appear as they're generated
- **Configurable Agent**: Name and behavior from environment variables
- **Clean Exit**: Graceful termination with goodbye message