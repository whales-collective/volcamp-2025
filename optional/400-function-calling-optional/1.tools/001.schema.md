# Function Calling

```mermaid
flowchart TD
    Start[<a href="main.go#L15">Program Start</a>]:::start --> Setup[<a href="main.go#L22">Setup OpenAI Client</a>]:::client
    Setup --> DefineTools[<a href="main.go#L28">Define Tools</a>]:::config

    DefineTools --> SpeakTool[<a href="main.go#L28">parler_de Tool</a>]:::tool
    DefineTools --> GreetTool[<a href="main.go#L43">dire_bonjour Tool</a>]:::tool

    SpeakTool --> UserMessage[<a href="main.go#L64">User Input</a>]:::input
    GreetTool --> UserMessage

    UserMessage --> LLMCall[<a href="main.go#L84">Call LLM with Tools</a>]:::api
    LLMCall --> ProcessTools[<a href="main.go#L102">Process Tool Calls</a>]:::process

    ProcessTools --> SpeakHandler{<a href="main.go#L106">parler_de?</a>}:::decision
    ProcessTools --> GreetHandler{<a href="main.go#L132">dire_bonjour?</a>}:::decision

    SpeakHandler -->|aligot| Andre[<a href="main.go#L123">André</a>]:::output
    SpeakHandler -->|truffade| Edouard[<a href="main.go#L125">Édouard</a>]:::output
    SpeakHandler -->|other| Vercingetorix[<a href="main.go#L127">Vercingetorix</a>]:::output

    GreetHandler --> Greeting[<a href="main.go#L135">Send Greeting</a>]:::greeting

    Andre --> EndNode[<a href="main.go#L138">Display Results</a>]:::final
    Edouard --> EndNode
    Vercingetorix --> EndNode
    Greeting --> EndNode

    classDef start fill:#e1f5fe,stroke:#01579b,stroke-width:3px,color:#000
    classDef client fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px,color:#000
    classDef config fill:#e8f5e8,stroke:#2e7d32,stroke-width:2px,color:#000
    classDef tool fill:#fff3e0,stroke:#f57c00,stroke-width:2px,color:#000
    classDef input fill:#f1f8e9,stroke:#689f38,stroke-width:2px,color:#000
    classDef api fill:#fce4ec,stroke:#c2185b,stroke-width:2px,color:#000
    classDef process fill:#e3f2fd,stroke:#1976d2,stroke-width:2px,color:#000
    classDef decision fill:#fff8e1,stroke:#f9a825,stroke-width:2px,color:#000
    classDef output fill:#e8eaf6,stroke:#5e35b1,stroke-width:2px,color:#000
    classDef greeting fill:#e0f2f1,stroke:#00796b,stroke-width:2px,color:#000
    classDef final fill:#ffebee,stroke:#d32f2f,stroke-width:3px,color:#000
```

## Simple Overview

**What it does:**
- Connects to a local AI model
- Defines 2 French language tools
- Processes multiple tool calls in parallel
- Routes responses based on subjects

**Tools:**
1. **parler_de** - Talk about a subject
   - Input: subject name
   - Output: Which expert to consult

2. **dire_bonjour** - Say hello
   - Input: person's name
   - Output: Greeting message

**Key Features:**
- **Parallel Processing**: Multiple tools run at once
- **Subject Routing**: Different experts for different topics
- **French Interface**: Tools and responses in French
- **Local Model**: Uses Docker-based model runner

**Flow:**
1. Load environment settings
2. Create OpenAI client
3. Define tools with parameters
4. Send user message to LLM
5. LLM decides which tools to call
6. Process each tool call
7. Display results

**Example Usage:**
User says: "I want to talk about truffade and say hello to Bob"
→ LLM calls both tools
→ Result: "Talk to Édouard" + "Hello Bob!"